{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight-Setting in Weighted Jensen-Shannon Divergence\n",
    "\n",
    "Goal: We know that using the weight vector of `[5,4,3,2,1]` makes the Jensen-Shannon divergence only *ordinal* tool to compare two distribution, while proportionality is not achieved. Our goal is to find out how this set of weights distorts the four important areas in quadrant plot, namely whether it consist of rectangular (or even square) areas or whether a more complicated distoriton occurs.  \n",
    "\n",
    "Approach: Examine the effect of weights and project the divergence of simulated distributions to quadrant plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula for weighted Jensen-Shannon divergence\n",
    "\n",
    "My own implementation - see bottom for trials with ready packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def djs(p, q, weights=[5,4,3,2,1]):\n",
    "    \"\"\"\n",
    "    My own implementation of standardized weighted Jensen-Shannon divergence.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p,q : sequence\n",
    "        Define the (discrete) distributions. ``pk[i]`` is the normalized probability of event ``i``.\n",
    "    wgh : sequence, optional\n",
    "        Weights to be applied, wgh[i] relates to p[i] and q[i]\n",
    "    Returns\n",
    "    -------\n",
    "    djs : float\n",
    "        The calculated divergence.\n",
    "    \"\"\"\n",
    "    \n",
    "    #set weights if no supplied\n",
    "    if weights == None:\n",
    "        weights = [4,3,2,1,0]\n",
    "        \n",
    "    # mixture\n",
    "    mx = [p + q for p,q in zip(p,q)] # NB: no normalization here!\n",
    "\n",
    "    # sum\n",
    "    part1 = [wi * pi * np.log(2*pi / mxi) for wi,pi,mxi in zip(weights,p,mx) if mxi>0 and pi>0]\n",
    "    part2 = [wi * qi * np.log(2*qi / mxi) for wi,qi,mxi in zip(weights,q,mx) if mxi>0 and qi>0]\n",
    "    djs = 1/2*(np.array(part1).sum() + np.array(part2).sum())\n",
    "    part1, part2, djs, djs == np.log(2)\n",
    "\n",
    "    # result with normalziation: NB: the factor only applies for weights of [5,4,3,2,1]!\n",
    "    return djs/(3*np.log(2))*np.sign(djs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal =     [0,0,0,0,1]\n",
    "medioplus = [0,0,0,1,0]\n",
    "medio =     [0,0,1,0,0]\n",
    "mediomin  = [0,1,0,0,0]\n",
    "worst =     [1,0,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "djs(ideal, worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259.00000000000006"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "djs(ideal, worst, weights=[777]*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-linearity of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "djs(ideal, worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83333333333333337"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "djs(ideal, mediomin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66666666666666674"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "djs(ideal, medio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "djs(ideal, medioplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "djs(ideal, ideal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated distributions\n",
    "Make up more realistic distributions consisting of more than one peak, compare the `djs` between them and the ideal one and examine the ordinality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*skipping for the moment*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euclidean distance\n",
    "*hypothesis*: Can we measure the distance between distributions using the most common metric in the 5D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.euclidean(ideal, ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.euclidean(ideal, medioplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.euclidean(ideal, medio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.euclidean(ideal, mediomin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.euclidean(ideal, worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion: Suffers from the same issue as with plain divergence: each pair of 'corners' in the cube has the same distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sand box: Efforts with other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import (comb, chndtr, entr, rel_entr, xlogy, ive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gist.github.com/zhiyzuo/f80e2b1cfb493a5711330d271a228a3d\n",
    "    \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "def jsd(p, q, base=np.e):\n",
    "    '''\n",
    "        Implementation of pairwise `jsd` based on  \n",
    "        https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence\n",
    "    '''\n",
    "    ## convert to np.array\n",
    "    p, q = np.asarray(p), np.asarray(q)\n",
    "    ## normalize p, q to probabilities\n",
    "    p, q = p/p.sum(), q/q.sum()\n",
    "    m = 1./2*(p + q)\n",
    "    return sp.stats.entropy(p,m, base=base)/2. + sp.stats.entropy(q, m, base=base)/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69314718056\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "p = [0,0,0,0,1] #ideal\n",
    "q = [1,0,0,0,0] #worst\n",
    "print(jsd(p,q))\n",
    "print(jsd(p,q) == scipy.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69314718055994529"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = [0,0,0,0,1] #ideal\n",
    "q = [0,0,1,0,0] #mediocre\n",
    "jsd(p,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dit.readthedocs.io/en/latest/measures/divergences/jensen_shannon_divergence.html\n",
    "import dit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dit.divergences.jensen_shannon_divergence as jsdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dit import Distribution, ScalarDistribution\n",
    "outcomes = ['A', 'B', 'C', 'D', 'E']\n",
    "pmf = [1/5]*5\n",
    "mydist = Distribution(outcomes, pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dit.divergences import jensen_shannon_divergence, kullback_leibler_divergence\n",
    "# X = dit.ScalarDistribution(['red', 'blue'], [1/2, 1/2])\n",
    "# Y = dit.ScalarDistribution(['blue', 'green'], [1/2, 1/2])\n",
    "# jensen_shannon_divergence([X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Distribution(outcomes, [0,0,0,0,1]) #ideal\n",
    "q = Distribution(outcomes, [1,0,0,0,0]) #worst\n",
    "m = Distribution(outcomes, [0,0,1,0,0]) #mediocre\n",
    "kullback_leibler_divergence(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ScalarDistribution(outcomes, [0,0,0,0,1]) #ideal\n",
    "q = ScalarDistribution(outcomes, [1,0,0,0,0]) #worst\n",
    "m = ScalarDistribution(outcomes, [0,0,1,0,0]) #mediocre\n",
    "wg = [5,4,3,2,1]\n",
    "#jsdw(dists=[p, q], weights= wg)\n",
    "#print(jsdw(p,q) == scipy.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ditException",
     "evalue": "Length of `dists` and `weights` must be equal.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mditException\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-2b480eaa00e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjensen_shannon_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/twisto/lib/python3.5/site-packages/dit/utils/units.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/twisto/lib/python3.5/site-packages/dit/divergences/jensen_shannon_divergence.py\u001b[0m in \u001b[0;36mjensen_shannon_divergence\u001b[0;34m(dists, weights)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# validation of `weights` is done in mixture_distribution,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# so we don't need to worry about it for the second part.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mmixture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixture_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mtwo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/twisto/lib/python3.5/site-packages/dit/distconst.py\u001b[0m in \u001b[0;36mmixture_distribution\u001b[0;34m(dists, weights, merge)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Length of `dists` and `weights` must be equal.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mditException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mditException\u001b[0m: Length of `dists` and `weights` must be equal."
     ]
    }
   ],
   "source": [
    "jensen_shannon_divergence([p, q], weights=wg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jensen_shannon_divergence([p, m])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
